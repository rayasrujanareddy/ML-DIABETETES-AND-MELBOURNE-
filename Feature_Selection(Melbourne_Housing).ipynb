{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrWWiA1QAnXWSHEKOqSleV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayasrujanareddy/ML-DIABETETES-AND-MELBOURNE-/blob/main/Feature_Selection(Melbourne_Housing).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Values Ratio"
      ],
      "metadata": {
        "id": "BYv89bY82BsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import numpy as np\n",
        "\n",
        "# Load the Melbourne housing dataset\n",
        "file_path = '/content/melbourne_housing_raw.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Calculate percentage of missing values for each column\n",
        "missing_percentage = data.isnull().mean() * 100\n",
        "\n",
        "# Step 2: Remove Features with more than 20% missing values, EXCLUDING 'Price'\n",
        "threshold = 20\n",
        "\n",
        "# Exclude 'Price' from the Features to drop\n",
        "Features_to_remove = missing_percentage[(missing_percentage > threshold) & (missing_percentage.index != 'Price')].index\n",
        "# Use 'columns' instead of 'Features' to specify columns to drop\n",
        "reduced_data = data.drop(columns=Features_to_remove) # Changed 'Features' to 'columns'\n",
        "\n",
        "print(\"\\nFeatures Removed (more than 20% missing):\", Features_to_remove)\n",
        "print(\"Dataset Shape after Feature Removal:\", reduced_data.shape)\n",
        "\n",
        "# Step 3: Train a Linear Regression model to predict 'Price'\n",
        "# Assuming 'Price' is the target variable and removing any remaining rows with missing values\n",
        "reduced_data.dropna(inplace=True)\n",
        "X = reduced_data.drop('Price', axis=1)\n",
        "y = reduced_data['Price']\n",
        "\n",
        "\n",
        "# ----> Convert categorical features to numerical using one-hot encoding\n",
        "X = pd.get_dummies(X, drop_first=True) # Use pandas get_dummies for one-hot encoding\n",
        "\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l6NduC_4Dsq",
        "outputId": "ef5a068a-ecec-48bf-a82c-71ebf42b8835"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features Removed (more than 20% missing): Index(['Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt',\n",
            "       'Lattitude', 'Longtitude'],\n",
            "      dtype='object')\n",
            "Dataset Shape after Feature Removal: (34857, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High Correlation Filter"
      ],
      "metadata": {
        "id": "Am4dEJeN2Crc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the Melbourne housing dataset\n",
        "file_path = '/content/melbourne_housing_raw.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Display initial dataset shape and check for correlation\n",
        "print(f\"Reduced dataset shape: {data.shape}\")\n",
        "\n",
        "# Step 2: Drop rows with missing target value (assuming 'Price' is the target)\n",
        "data = data.dropna(subset=['Price'])\n",
        "\n",
        "# Step 3: Drop non-numerical columns for correlation analysis\n",
        "numeric_data = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Step 4: Calculate correlation matrix\n",
        "corr_matrix = numeric_data.corr().abs()\n",
        "\n",
        "# Step 5: Identify Features with correlation greater than 0.85\n",
        "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.85)]\n",
        "\n",
        "print(\"\\nFeatures with high correlation (> 0.85):\", to_drop)\n",
        "\n",
        "# Step 6: Remove highly correlated features\n",
        "reduced_data = numeric_data.drop(columns=to_drop)\n",
        "\n",
        "# Step 7: Separate features and target (Price)\n",
        "X = reduced_data.drop('Price', axis=1)  # Features\n",
        "y = reduced_data['Price']  # Target\n",
        "\n",
        "# Impute or drop missing values in X before splitting\n",
        "X.dropna(inplace=True)\n",
        "y = y[X.index]  # Align y with dropped rows in X\n",
        "\n",
        "# Step 8: Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 9: Train a Linear Regression model on the reduced dataset\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 10: Predict and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# The print statement was incorrectly indented\n",
        "mse = mean_squared_error(y_test, y_pred) # Calculate MSE\n",
        "print(f\"Mean Squared Error after removing features with high correlation: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp-dwi1YlGPM",
        "outputId": "2891a965-e0fc-4020-9b25-0177c5e32ef9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced dataset shape: (34857, 20)\n",
            "\n",
            "Features with high correlation (> 0.85): ['Bedroom2']\n",
            "Mean Squared Error after removing features with high correlation: 139263362178.95044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Low Variance Filter"
      ],
      "metadata": {
        "id": "HXg5MSI-2D_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Handling categorical variables (optional, if present)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Step 2: Remove features with low variance\n",
        "threshold = 0.01  # Define a variance threshold\n",
        "selector = VarianceThreshold(threshold=threshold)\n",
        "X_high_variance = selector.fit_transform(X)\n",
        "\n",
        "# Step 3: Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_high_variance, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train a Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error after removing low-variance features:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8rS9sIWwMmU",
        "outputId": "37ed77b8-26c6-41e9-f346-bec1f5edfef3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error after removing low-variance features: 143982083160.5457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Feature Selection"
      ],
      "metadata": {
        "id": "hYsCB8-j2Fhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold, SequentialFeatureSelector\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Handling categorical variables (optional, if present)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Step 2: Remove features with low variance\n",
        "threshold = 0.01  # Define a variance threshold\n",
        "selector = VarianceThreshold(threshold=threshold)\n",
        "\n",
        "# Store original feature names\n",
        "original_features = X.columns\n",
        "X_high_variance = selector.fit_transform(X)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "# Get the names of the selected features using the indices\n",
        "selected_features = original_features[selected_feature_indices]\n",
        "\n",
        "# Step 3: Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_high_variance, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train a Linear Regression model\n",
        "# Create a DataFrame for X_train with the selected feature names\n",
        "X_train = pd.DataFrame(X_train, columns=selected_features)\n",
        "# Create a DataFrame for X_test with the selected feature names\n",
        "X_test = pd.DataFrame(X_test, columns=selected_features)\n",
        "\n",
        "model = LinearRegression()\n",
        "sfs = SequentialFeatureSelector(model, n_features_to_select='auto', direction='forward')\n",
        "sfs.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features_sfs = X_train.columns[sfs.get_support()]\n",
        "print(\"\\nSelected features from forward feature selection:\", selected_features_sfs)\n",
        "\n",
        "# Train and evaluate with selected features\n",
        "X_train_selected = sfs.transform(X_train)\n",
        "X_test_selected = sfs.transform(X_test)\n",
        "\n",
        "# Recreate DataFrames with selected features\n",
        "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features_sfs)\n",
        "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features_sfs)\n",
        "\n",
        "model.fit(X_train_selected, y_train)\n",
        "y_pred = model.predict(X_test_selected)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"\\nMean Squared Error with forward selected features:\", mse)"
      ],
      "metadata": {
        "id": "DTaBfAID2F_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e6d332-d208-41d6-8a6d-dd2d3d755c74"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Selected features from forward feature selection: Index(['Distance', 'Bathroom', 'BuildingArea', 'YearBuilt', 'Longtitude'], dtype='object')\n",
            "\n",
            "Mean Squared Error with forward selected features: 161311987518.01767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backward Feature Elimination"
      ],
      "metadata": {
        "id": "2zqNN8nS2Gq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/melbourne_housing_raw.csv')\n",
        "\n",
        "# Drop rows with missing target values\n",
        "data = data.dropna(axis=0, subset=['Price'])\n",
        "\n",
        "# Select target and features\n",
        "y = data['Price']\n",
        "X = data.drop(columns=['Price'])\n",
        "\n",
        "# Remove categorical columns for simplicity\n",
        "X = X.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Train a Random Forest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get initial feature importances\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "# Backward Feature Elimination\n",
        "# Limit the number of features to remove to avoid an empty DataFrame\n",
        "max_features_to_remove = len(X_train.columns) - 1  # Keep at least one feature\n",
        "\n",
        "for i in range(max_features_to_remove):\n",
        "    # Get the least important feature\n",
        "    feature_importances = model.feature_importances_\n",
        "    least_important_index = feature_importances.argmin()\n",
        "    least_important = X_train.columns[least_important_index]\n",
        "\n",
        "    # Remove the least important feature\n",
        "    print(f\"Removing feature: {least_important}\")\n",
        "    X_train = X_train.drop(columns=[least_important])\n",
        "    X_test = X_test.drop(columns=[least_important])\n",
        "\n",
        "    # Re-train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "    # Print remaining features after each iteration\n",
        "    if len(X_train.columns) == 1:\n",
        "        print(f\"Remaining features: {list(X_train.columns)}\")\n",
        "        break  # Stop when only one feature remains\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwJR52qMybpQ",
        "outputId": "41b0dd81-7ea3-4df4-db8a-68d4e8c29e97"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing feature: Bedroom2\n",
            "Mean Squared Error: 97867133109.50856\n",
            "Removing feature: Car\n",
            "Mean Squared Error: 97972656014.63878\n",
            "Removing feature: Bathroom\n",
            "Mean Squared Error: 99640140583.48747\n",
            "Removing feature: YearBuilt\n",
            "Mean Squared Error: 101623748900.94626\n",
            "Removing feature: Propertycount\n",
            "Mean Squared Error: 103897503319.53635\n",
            "Removing feature: Lattitude\n",
            "Mean Squared Error: 105570006035.0283\n",
            "Removing feature: BuildingArea\n",
            "Mean Squared Error: 115233044858.10635\n",
            "Removing feature: Longtitude\n",
            "Mean Squared Error: 122347047183.65295\n",
            "Removing feature: Landsize\n",
            "Mean Squared Error: 144426955105.20114\n",
            "Removing feature: Rooms\n",
            "Mean Squared Error: 296076986588.5735\n",
            "Removing feature: Distance\n",
            "Mean Squared Error: 296509137061.96814\n",
            "Remaining features: ['Postcode']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest\n"
      ],
      "metadata": {
        "id": "L8oVPvwW2Hwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error # Import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/melbourne_housing_raw.csv')\n",
        "\n",
        "# Drop rows with missing target values\n",
        "data = data.dropna(axis=0, subset=['Price'])\n",
        "\n",
        "# Select target and features\n",
        "y = data['Price']\n",
        "X = data.drop(columns=['Price'])\n",
        "\n",
        "# Remove categorical columns for simplicity\n",
        "X = X.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Train a Random Forest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = model.feature_importances_\n",
        "features = X_train.columns\n",
        "\n",
        "# Display the most important features\n",
        "feature_importance = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "print(feature_importance.sort_values(by='Importance', ascending=False))\n",
        "\n",
        "# Assuming you want to remove the least important feature for demonstration\n",
        "# Get the least important feature\n",
        "least_important_feature = feature_importance.sort_values(by='Importance').iloc[0]['Feature']\n",
        "\n",
        "# Drop the least important feature from training and test sets\n",
        "X_train_reduced = X_train.drop(columns=[least_important_feature])\n",
        "X_test_reduced = X_test.drop(columns=[least_important_feature])\n",
        "\n",
        "# Re-train the model with reduced features - THIS IS THE 'model_reduced'\n",
        "model_reduced = RandomForestRegressor(n_estimators=100, random_state=0) # Define model_reduced\n",
        "model_reduced.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Make predictions and evaluate the reduced model\n",
        "y_pred_reduced = model_reduced.predict(X_test_reduced) # Use model_reduced for prediction\n",
        "mse_reduced = mean_squared_error(y_test, y_pred_reduced)\n",
        "print(f\"Removed feature: {least_important_feature}, MSE after removal: {mse_reduced}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USPtXo_oVXrr",
        "outputId": "11999f0e-1dc6-4f18-b5ae-f00cbf394ddb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Feature  Importance\n",
            "1        Distance    0.270842\n",
            "0           Rooms    0.216239\n",
            "2        Postcode    0.181843\n",
            "6        Landsize    0.087393\n",
            "10     Longtitude    0.057649\n",
            "7    BuildingArea    0.051040\n",
            "9       Lattitude    0.039213\n",
            "11  Propertycount    0.033881\n",
            "8       YearBuilt    0.027321\n",
            "4        Bathroom    0.016745\n",
            "5             Car    0.013324\n",
            "3        Bedroom2    0.004510\n",
            "Removed feature: Bedroom2, MSE after removal: 97867133109.50856\n"
          ]
        }
      ]
    }
  ]
}